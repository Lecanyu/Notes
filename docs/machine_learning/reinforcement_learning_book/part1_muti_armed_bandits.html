<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Multi-armed Bandits</title>
  <meta name="description" content="Personal notes (memorandum).">


  <link rel="stylesheet" href="/Notes/css/tufte.css">	
  

  <!-- Google Fonts loaded here depending on setting in _data/options.yml true loads font, blank does not-->
  
    <link href='//fonts.googleapis.com/css?family=Lato:400,400italic' rel='stylesheet' type='text/css'>
  
  <!-- Load up MathJax script if needed ... specify in /_data/options.yml file-->
  
    <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  

  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-75587219-1', 'auto');
  ga('send', 'pageview');

  </script>

  <link rel="canonical" href="http://localhost:4000/Notes/machine_learning/reinforcement_learning_book/part1_muti_armed_bandits">
  <link rel="alternate" type="application/rss+xml" title="Notes" href="http://localhost:4000/Notes/feed.xml" />
</head>

  <body>
    <!--- Header and nav template site-wide -->
<header>
    <nav class="group">
        <a href="/Notes/">Contents</a>
		<a href="https://github.com/Lecanyu/Notes">Github</a>
	</nav>
</header>

    <article class="group">
      <h1>Multi-armed bandits</h1>
<p class="subtitle"></p>


<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    TeX: {
      Macros: {
        e: "\\epsilon",
        xti: "x^{(i)}",
        yti: "y^{(i)}",
        bfy: "{\\bf y}",
        bfx: "{\\bf x}",
        bfg: "{\\bf g}",
        bfbeta: "{\\bf \\beta}",
        tp: "\\tilde p",
        pt: "p_\\theta",
        Exp: "{\\mathbb{E}}",
        Ind: "{\\mathbb{I}}",
        KL: "{\\mathbb{KL}}",
        Dc: "{\\mathcal{D}}",
        Tc: "{\\mathcal{T}}",
        Xc: "{\\mathcal{X}}",
        note: ["\\textcolor{blue}{[NOTE: #1]}",1]
      }
    }
  });
</script>


<h2 id="action-value-estimation">Action-value estimation</h2>

<p>The action-value function usually can be updated according to below equation:</p>

<div class="mathblock"><script type="math/tex; mode=display">
Q_{new}(A) \gets Q_{old}(A) + \alpha_{n}[Q_{target}(A) - Q_{old}(A)]
</script></div>
<p>The learning rate <script type="math/tex">\alpha_n</script> here has been treated as the function w.r.t. update times <script type="math/tex">n</script>.</p>

<p><script type="math/tex">Q_{new}(A)</script> can converge when below two conditions are satisfied.</p>

<div class="mathblock"><script type="math/tex; mode=display">
\sum_{n=1}^\infty \alpha_n = \infty \\
\sum_{n=1}^\infty \alpha_n^2 < \infty
</script></div>

<p>The first condition is required to guarantee that the steps are large enough to eventually overcome any initial conditions or random fluctuations.</p>

<p>The second condition guarantees that eventually the steps become small enough to assure convergence.</p>

<p>Note that <script type="math/tex">\alpha</script> usually is set to a constant in many practical RL problems, which violates the second condition. Hence, the <script type="math/tex">Q_{new}</script> wonâ€™t converge. However, this actually can be a desirable property in highly nonstationary environment (i.e. the true state-value can be changed after sampling each time).</p>

<h2 id="several-exploration-strategies">Several exploration strategies</h2>

<ol>
  <li>
    <p><script type="math/tex">\epsilon</script>-greedy</p>
  </li>
  <li>
    <p>Upper confidence bound (UCB)</p>

    <p>This method is adopted in recent AlphaGo monte carlo tree search.</p>

    <p>The action will be taken according to below rule</p>

    <div class="mathblock"><script type="math/tex; mode=display">
 a = \mathop{\arg\min}_{a} [Q_t(a) + c \sqrt \frac{\ln t}{N_t(a)}]
 </script></div>
    <p>where <script type="math/tex">Q_t(a)</script> is the action-value result at time step <script type="math/tex">t</script>. <script type="math/tex">N_t(a)</script> denotes the number of times that action <script type="math/tex">a</script> has been selected prior to time <script type="math/tex">t</script>.</p>

    <p>The idea of this action selection is that each time <script type="math/tex">a</script> is selected, the uncertainty of action <script type="math/tex">a</script> is presumbly reduced, and thus the probability of selecting <script type="math/tex">a</script> will decrease.</p>
  </li>
  <li>
    <p>Optimistic initial values</p>

    <p>Setting a larger initial estimates can encourage exploring automatically in some special cases.</p>
  </li>
  <li>
    <p>Gradient bandit algorithm</p>

    <p>Directly define a numerical preference for each action selection.</p>
  </li>
</ol>




    </article>
    <span class="print-footer">Multi-armed Bandits - Canyu Le</span>
    <footer>
  <hr class="slender">
  <!-- <ul class="footer&#45;links"> -->
  <!--   <li><a href="mailto:hate@spam.net"><span class="icon&#45;mail"></span></a></li>     -->
  <!--    -->
  <!--     <li> -->
  <!--       <a href="//www.twitter.com/twitter_handle"><span class="icon-twitter"></span></a> -->
  <!--     </li> -->
  <!--    -->
  <!--     <li> -->
  <!--       <a href="//plus.google.com/+googlePlusName"><span class="icon-googleplus"></span></a> -->
  <!--     </li> -->
  <!--    -->
  <!--     <li> -->
  <!--       <a href="//github.com/GithubHandle"><span class="icon-github"></span></a> -->
  <!--     </li> -->
  <!--    -->
  <!--     <li> -->
  <!--       <a href="//www.flickr.com/photos/FlickrUserID"><span class="icon-flickr"></span></a> -->
  <!--     </li> -->
  <!--    -->
  <!--     <li> -->
  <!--       <a href="/feed"><span class="icon-feed"></span></a> -->
  <!--     </li> -->
  <!--      -->
  <!-- </ul> -->
<div class="credits">
<!-- <span>&#38;copy; 2020 <!&#45;&#45; &#38;#38;nbsp;&#38;#38;nbsp;CANYU LE &#45;&#45;></span></br> <br> -->
<span>Site created with <a href="//jekyllrb.com">Jekyll</a> using the <a href="//github.com/clayh53/tufte-jekyll">Tufte theme</a>. &copy; 2020</span> 
</div>  
</footer>

  </body>
</html>
