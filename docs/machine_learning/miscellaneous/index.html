<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Miscellaneous</title>
  <meta name="description" content="Personal notes (memorandum).">


  <link rel="stylesheet" href="/Notes/css/tufte.css">	
  

  <!-- Google Fonts loaded here depending on setting in _data/options.yml true loads font, blank does not-->
  
    <link href='//fonts.googleapis.com/css?family=Lato:400,400italic' rel='stylesheet' type='text/css'>
  
  <!-- Load up MathJax script if needed ... specify in /_data/options.yml file-->
  
    <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  

  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-75587219-1', 'auto');
  ga('send', 'pageview');

  </script>

  <link rel="canonical" href="http://localhost:4000/Notes/machine_learning/miscellaneous/">
  <link rel="alternate" type="application/rss+xml" title="Notes" href="http://localhost:4000/Notes/feed.xml" />
</head>

  <body>
    <!--- Header and nav template site-wide -->
<header>
    <nav class="group">
        <a href="/Notes/">Contents</a>
		<a href="https://lecanyu.github.io/">Resume</a>
		<a href="https://github.com/Lecanyu/Notes">Github</a>
	</nav>
</header>

    <article class="group">
      <h1>Miscellaneous</h1>
<p class="subtitle"></p>


<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    TeX: {
      Macros: {
        e: "\\epsilon",
        xti: "x^{(i)}",
        yti: "y^{(i)}",
        bfy: "{\\bf y}",
        bfx: "{\\bf x}",
        bfg: "{\\bf g}",
        bfbeta: "{\\bf \\beta}",
        tp: "\\tilde p",
        pt: "p_\\theta",
        Exp: "{\\mathbb{E}}",
        Ind: "{\\mathbb{I}}",
        KL: "{\\mathbb{KL}}",
        Dc: "{\\mathcal{D}}",
        Tc: "{\\mathcal{T}}",
        Xc: "{\\mathcal{X}}",
        note: ["\\textcolor{blue}{[NOTE: #1]}",1]
      }
    }
  });
</script>


<p>Some basic machine learning knowledge which are frequently applied in various research (also often asked in interview). I wrote them down for review.</p>

<h2 id="pareto-optimality">Pareto optimality</h2>
<p>It is a resource allocation state in which it is impossible that reallocate the resources so as to improve an individual situation without making other individuals worse off.</p>

<p>It is a minimum notion of efficiency but unnecessarily lead to desire results since it doesn‚Äôt take fairness and equality into account.</p>

<h2 id="pareto-improvement">Pareto improvement</h2>
<p>It means we can reallocate the limited resources to make some individuals better off without making any other individuals worse off.</p>

<h2 id="precision-recall-estimation">Precision-recall estimation</h2>
<div class="mathblock"><script type="math/tex; mode=display">
Recall = \frac{TP}{TP+FN}, \quad
Precision = \frac{TP}{TP+FP}
</script></div>

<p>False positive (FP): classify the negative class into positive category.</p>

<p>False negative (FN): classify the positive class into negative category.</p>

<h2 id="bias-and-variance">Bias and variance</h2>
<p>Bias is used to describe how close it is between the prediction and true value.</p>

<p>Variance is used to describe how concentrated the predictions are.</p>

<p>Overfitting usually lead to high variance since it is trained to fit the noises in training data.</p>

<p>Underfitting usually lead to high bias since it is unable to capture enough correlation between input and target.</p>

<h2 id="classification-and-regression">Classification and regression</h2>
<p>The training target in classification is discrete.</p>

<p>The training target in regression is continuous.</p>

<h2 id="supervised-learning-unsupervised-learning-semi-supervised-learning">Supervised learning, unsupervised learning, semi-supervised learning</h2>
<p>The training data is labeled in supervised learning like classification</p>

<p>The training data is unlabeled in unsupervised learning like clustering, generative adversarial network, EM algorithm, PCA and etc.</p>

<h2 id="off-policy-and-on-policy">Off-policy and on policy</h2>
<p>Off-policy is the training target of a policy is different from the behavior policy like ùúÄ-greedy (more exploration)</p>

<p>On policy is the training target of a policy is exact the same with the behavior policy. (less exploration)</p>

<p>On policy can converge faster than off-policy.</p>

<h2 id="feature-selection-how-to-select-feature-from-massive-statistical-data">Feature selection (how to select feature from massive statistical data)</h2>
<p>Filtering: according to the feature variance</p>

<p>Wrapper: we can randomly pick some features to train and evaluate the result</p>

<p>Embedded: we can use a machine learning method to train first and then check how important those features are.</p>

<h2 id="generative-model">Generative model</h2>
<p>All types of generative models aims at learning the true distribution of training data so as to generate new data point with some variations. But it is not always possible to learn the exact data distribution.</p>

<p>It belongs to unsupervised learning (we don‚Äôt need to label the training data).</p>

<p>Two types of generative models:</p>
<ul>
  <li>Variational autoencoder (VAE)</li>
  <li>Generative Adversarial Networks (GAN) 
<label for="1," class="margin-toggle sidenote-number"></label><input type="checkbox" id="1," class="margin-toggle" /><span class="sidenote">check <a href="https://towardsdatascience.com/generative-adversarial-networks-explained-34472718707a">here</a> and <a href="https://arxiv.org/pdf/1406.2661.pdf">paper</a> for detailed introducation.  </span></li>
  <li><em>The generator network and discriminator network (evaluator).</em></li>
</ul>
<figure><figcaption></figcaption><img src="/Notes/assets/machine_learning/generative_adversarial_network.png" /></figure>
<figure><figcaption></figcaption><img src="/Notes/assets/machine_learning/generative_adversarial_network_2.png" /></figure>

<h2 id="p-np-np-complete-np-hard">P, NP, NP-Complete, NP-hard</h2>
<p>P is the problem that we can find a solution which can be finished in polynomial time. 
<label for="mf-id-whatever" class="margin-toggle">‚äï</label><input type="checkbox" id="mf-id-whatever" class="margin-toggle" /><span class="marginnote"><img class="fullwidth" src="/Notes/assets/machine_learning/P_NP.png" /><br />The relationship between P, NP, NP-hard and NP-Complete. </span></p>

<p>NP is the problem that we may not be able to find a polynomial time complexity solution but we can validate if a specific solution is correct or not within polynomial time.</p>

<p>NP-hard is a more general problem that some NP problems can reduce to within polynomial time. Once a NP-hard problem is solved, all such reducible NP problems will be solved. (Note: Sometimes, after NP reduce to NP-hard, this NP-hard problem may not be validated within polynomial time).
The global composition in jigsaw puzzle solving can be seen as a SAT problem variant, but it cannot be validated within polynomial time. So it belongs to NP-hard.</p>

<p>NP-complete is overlap between NP-hard and NP, which means they are reduced from NP and still can be validated within polynomial time.</p>

<p>SAT (satisfiability) problem: if we can find a Boolean assignment that make a system output true. For example, we cannot find such assignment for  <script type="math/tex">\neg p \land p</script>, but we can find for <script type="math/tex">p \land q</script>.</p>

<p>Variant: 2-SAT and 3-SAT. See this intuitive <a href="https://www.zhihu.com/question/55516280/answer/145138234">example</a> (ËøáÂπ¥‰∫ÜÔºåÊ≠£ÊâìÁÆóÁÉßÂπ¥Â§úÈ•≠ blabla‚Ä¶)</p>

<p>Problem Reduce: this means we can convert a problem into a more general (usually more difficult) problem. For example, problem A: find the minimum element in an array. Problem B: sort the whole array. We can say A can be reduce to B, since if we can solve the problem B, problem A will be solved trivially.</p>

<h2 id="the-advantage-of-max-pooling-layer">The advantage of max pooling layer</h2>
<p>Reduce the number of parameters. To avoid over-fitting</p>

<p>Increase the perceptual field</p>

<p>Extract the main features.</p>

<h2 id="convolutional-neural-network">Convolutional Neural Network</h2>
<figure><figcaption></figcaption><img src="/Notes/assets/machine_learning/CNN_filter_calc.png" /></figure>

<h2 id="batch-normalization">Batch normalization</h2>
<figure><figcaption></figcaption><img src="/Notes/assets/machine_learning/batch_normalization.png" /></figure>

<p>Suppose input= [batch, height, width, depth]. 
If we use axes= [0,1,2] to calculate (e.g. mean, var = tf.nn.moments(input, axes=[0, 1, 2])), then the output will be a 1-D vector with size=depth. 
If we use axes=[0] to calculate, then the output will be a 3-D vector with size=[height, width, depth]. The picture below demonstrates this 3-D vector case.</p>

<figure><figcaption></figcaption><img src="/Notes/assets/machine_learning/batch_normalization_ex.png" /></figure>

<h2 id="recurrent-neural-network-rnn">Recurrent Neural Network (RNN)</h2>
<p>An tutorial and introduction about <a href="http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/">RNN</a></p>

<figure><figcaption></figcaption><img src="/Notes/assets/machine_learning/RNN.png" /></figure>

<h2 id="hidden-markov-model">Hidden Markov Model</h2>
<p>An specific dice <a href="https://www.zhihu.com/question/20962240">example</a> will help to understand.</p>

<p>The basic elements:
Transition matrix, emission matrix, initial state.</p>

<p>Three basic problems:</p>
<ol>
  <li>Given the HMM model, how to calculate the probability of an observation. (forward algorithm)</li>
  <li>Given the HMM model and an observation, how to estimate which the most possible hidden state sequences are. (Viterbi algorithm, dynamic programming)</li>
  <li>Given the observation data, how to estimate the model parameters. (learning problem, Baum‚ÄìWelch algorithm)</li>
</ol>

<p>Note:
In the learning problem, 
the target of forward algorithm is to calculate the <script type="math/tex">\alpha_i(t) = P(X_{t=i}, y_1,y_2, ..., y_t)</script>.
The target of backward algorithm is to calculate the <script type="math/tex">\beta_i(t) = P(y_{t+1}, y_{t+2}, ..., y_T|X_{t=i})</script>.
The target of forward-backward algorithm is to calculate the <script type="math/tex">\gamma_i(t) = P(X_{t=i}|y_1, y_2, ..., y_T)</script>.</p>

<p>For the details, please check <a href="https://en.wikipedia.org/wiki/Baum%E2%80%93Welch_algorithm">here</a></p>

<h2 id="em-expectation-maximization-algorithm">EM (Expectation-Maximization) algorithm</h2>
<p>An intuitive <a href="https://www.youtube.com/watch?v=REypj2sy_5U">tutorial</a>.</p>

<p>EM algorithm is an unsupervised learning.</p>

<h2 id="maximum-likelihood-vs-maximum-a-posterior-map">Maximum likelihood vs Maximum A Posterior (MAP)</h2>
<p><script type="math/tex">P(X|Y) = \frac{P(Y|X) * P(X)}{P(Y)}</script> &lt;=&gt; <script type="math/tex">Posterior = \frac{Likelihood * Prior}{Evidence}</script>.</p>

<p>Usually given the training data <script type="math/tex">D</script>, our target is to maximize the posterior <script type="math/tex">P(\theta|D)</script>, where <script type="math/tex">\theta</script> is the model parameters. 
To do that, we usually have two approaches:</p>

<ol>
  <li>
    <p>Maximum likelihood.
Since <script type="math/tex">P(\theta|D)=\frac{P(D|\theta)P(\theta)}{P(D)}</script>, if we can assume the prior is a constant, then <script type="math/tex">\max P(\theta|D) = \max P(D|\theta)</script></p>
  </li>
  <li>
    <p>Maximum A Posterior (MAP).
Sometimes, we may not be able to make such assumption that the prior is a constant. Instead, prior may satisfy an unknown distribution. In this case, the target is  <script type="math/tex">P(\theta|D) =  \mathop{\arg\min}_{\theta} P(D|\theta)P(\theta)</script>. Since every data is generated independently, we have <script type="math/tex">P(\theta|D) =  \mathop{\arg\min}_{\theta} \Pi_i^n P(D=x_i|\theta)P(\theta)</script>.</p>
  </li>
</ol>

<h2 id="a-systematic-probabilistic-graph-model-course">A systematic probabilistic graph model course</h2>
<p>https://ermongroup.github.io/cs228-notes/</p>

<h2 id="several-concepts-need-to-be-distinguished">Several concepts need to be distinguished</h2>
<ol>
  <li>Bayesian Network</li>
  <li>Markov Random Field</li>
  <li>Conditional Random Field</li>
  <li>Markov Chain</li>
  <li>Hidden Markov Model</li>
  <li>Markov Decision Process</li>
</ol>

<h2 id="how-to-simulate-a-random-number-which-satisfy-a-probabilistic-distribution">How to simulate a random number which satisfy a probabilistic distribution</h2>
<ol>
  <li>Inverse transform method</li>
  <li>Acceptance rejection method</li>
</ol>

<p>Check <a href="http://blog.codinglabs.org/articles/methods-for-generating-random-number-distributions.html">here</a></p>

<h2 id="why-divide-n-1-to-get-unbiased-variance-estimation-in-sampling-data">Why divide n-1 to get unbiased variance estimation in sampling data</h2>
<p>http://blog.sina.com.cn/s/blog_c96053d60101n24f.html</p>

<h2 id="a-good-systematic-chinese-tutorial-for-machine-learning">A good systematic Chinese tutorial for machine learning</h2>
<p>https://nndl.github.io/</p>

<p>The summary of <a href="https://nndl.github.io/chap-%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80.pdf">math</a> part is a good material for reviewing the math background.</p>

<h2 id="information-theory">Information theory</h2>
<p>Refer to <a href="https://nndl.github.io/chap-%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80.pdf">here</a> for detailed introducation.</p>

<p>Encode length for a random variable <script type="math/tex">X=x</script>, <script type="math/tex">I(x)= -\log p(x)</script>.</p>

<p>Entropy: the average length for optimal encoding the whole of random variable X.  <script type="math/tex">H(x) = -\sum_x p(x) \log p(x)</script>. 
The more stochastic variable is, the larger entropy is.</p>

<div class="mathblock"><script type="math/tex; mode=display">
\mbox{Joint entropy:  } H(x, y) \\
\mbox{Conditional entropy:  } H(x|y) \\
H(x|y) = H(x,y) - H(y)
</script></div>

<p>Cross-entropy: the average encoding length when we use distribution <script type="math/tex">q</script> to encode information <script type="math/tex">x</script> whose real distribution is <script type="math/tex">p</script>.</p>
<div class="mathblock"><script type="math/tex; mode=display">
H(p,q)= -\sum_x p(x) \log q(x)
</script></div>
<p>Obviously, <script type="math/tex">H(p,q)=H(p)</script>, when <script type="math/tex">p(x)=q(x)</script>. We have minimum <script type="math/tex">H(p,q)</script>, when <script type="math/tex">p(x)=q(x)</script>.</p>

<p>Kullback-Leibler divergence (KL-divergence):</p>
<div class="mathblock"><script type="math/tex; mode=display">
H(p||q) = \sum_x p(x) \log \frac{p(x)}{q(x)} = H(p,q) - H(p) >= 0
</script></div>
<p>The meaning of KL-divergence is very similar with cross-entropy. 
Both of them measure how different between distribution <script type="math/tex">p(x)</script> and <script type="math/tex">q(x)</script>. So when <script type="math/tex">p(x)</script> is given, the optimization process of <script type="math/tex">H(p||q)</script> and <script type="math/tex">H(p,q)</script> is the same.
Comparing with cross-entropy, KL-divergence measures the absolute difference. When <script type="math/tex">p(x)=q(x)</script>, <script type="math/tex">H(p||q)=0</script>.</p>

<h2 id="logistic-regression">logistic regression</h2>
<p>sigmoid function <script type="math/tex">f(x; w)=\frac{1}{1+e^{-wx}}</script>: convert linear classification result to a probability.</p>

<p>maximize likelihood =&gt; solve the parameters in linear classification.</p>

<p>The key here is that sigmoid function normalize raw result into 0 and 1. Then we can construct below likelihood.</p>

<div class="mathblock"><script type="math/tex; mode=display">
\max P(w|Y) <=> \max P(Y|X, w) = \Pi_{i=1}^n f^{y_i}(x_i; w)(1-f(x_i;w))^{1-y_i}
</script></div>

<p>Apply logarithm on both side.</p>
<div class="mathblock"><script type="math/tex; mode=display">
\log P(y|x, w) = \sum_{i=1}^n y_i\log f(x_i;w) + (1-y_i)\log (1-f(x_i; w))
</script></div>

<p>This is equivalent to cross-entropy. And then we can apply gradient descend to optimization.</p>

<p>Check <a href="https://tech.meituan.com/intro_to_logistic_regression.html">here</a> for details.</p>

<h2 id="support-vector-machine-and-core-function">Support Vector Machine and Core function</h2>
<p>Will do</p>

<h2 id="kalman-filter">Kalman filter</h2>
<p>It is a algorithm for accurately estimating or predicting based on multiple observed data.</p>

<p>A classic example is SLAM in which we have multiple data collecting sensors like odometry, IMU and visual features. The Kalman filter is to solve how to reliably combine all sensor data and estimate a accurate pose.</p>

<h2 id="cross-entropy-instead-of-mean-square-error-mse-as-the-loss-function-in-classification">Cross-entropy instead of mean square error (MSE) as the loss function in classification?</h2>
<p>when we do classification, we usually apply softmax (this is an important premise) to normalize the output value to 0-1. 
In this case, the gradient of MSE loss will be prone to 0 when the prediction is closed to 0 or 1. This will lead to slow convergence.
On the contrary, the gradient of cross-entropy is linear with the prediction changing. When the prediction is closed to the label, the gradient will be small and vice versa.</p>

<h3 id="-cross-entropy">* Cross-entropy</h3>
<div class="mathblock"><script type="math/tex; mode=display">
p(x_i) = softmax(x_i) = \frac{e^{x_i}}{\sum_i e^{x_i}} \\
f(x) = -\sum_i y_i \log p(x_i)
</script></div>
<p>where <script type="math/tex">f(x)</script> is the objective cross-entropy function. To minimize it, we calculate the gradient w.r.t. <script type="math/tex">x_i</script></p>

<div class="mathblock"><script type="math/tex; mode=display"> 
\frac{\partial f(x)}{\partial x_i} = - \frac{y_i}{p(x_i)}p^{'}(x_i) \\ 
p^{'}(x_i) = \frac{\partial p(x_i)}{\partial x_i} = p(x_i) - p^2(x_i)
</script></div>
<p>So we have</p>
<div class="mathblock"><script type="math/tex; mode=display">
\frac{\partial f(x)}{\partial x_i} = - \frac{y_i}{p(x_i)}p^{'}(x_i) = -y_i (1-p(x_i))
</script></div>
<p>When <script type="math/tex">p(x_i)</script> is closed to 1, the gradient will be prone to 0. (Remember that we use one-hot encoding to represent <script type="math/tex">\mathbf{y}, \mathbf{x}</script>)</p>

<h3 id="-mse">* MSE</h3>
<div class="mathblock"><script type="math/tex; mode=display">
f(x) = \sum_i (y_i - p(x_i))^2 \\ 
\frac{\partial f(x)}{\partial x_i} = 2(y_i - p(x_i))(-p^{'}(x_i)) = -2(y_i - p(x_i))(p(x_i) - p^2(x_i))
</script></div>
<p>So we have the gradient</p>
<div class="mathblock"><script type="math/tex; mode=display">
\frac{\partial f(x)}{\partial x_i} = -2p(x_i)(1-p(x_i))(y_i - p(x_i))
</script></div>
<p>When <script type="math/tex">p(x_i)</script> is closed to 0 and 1, the gradient will be closed to 0. This is not desirable and will slow down the learning process. Because if <script type="math/tex">y_i = 1, p(x_i) = 0</script>, we hope the learning step is large, but the gradient is 0.</p>

<h2 id="the-property-of-softmax">The property of softmax</h2>
<ol>
  <li>property: the big value will take a large portion of the probability.</li>
  <li>potential drawback: exponential problem.</li>
</ol>

<h2 id="covariance-and-correlation-coefficients">Covariance and correlation coefficients</h2>
<p>Covariance is a measure of how two variables change together, but its magnitude is unbounded, so it is difficult to interpret. By dividing covariance by the product of the two standard deviations, one can calculate the normalized version of the statistic. This is the correlation coefficient.</p>
<ol>
  <li>Covariance: represent the unnormalized correlation.</li>
  <li>Correlation coefficient: represent the normalized correlation.</li>
</ol>
<div class="mathblock"><script type="math/tex; mode=display">
\rho_{xy} = \frac{Cov(x, y)}{\sigma_x \sigma_y}
</script></div>

<p>Refer to <a href="https://www.investopedia.com/terms/c/correlationcoefficient.asp">here</a> for details.</p>

<h2 id="normal-distribution-and-multivariate-normal-distribution">Normal distribution and multivariate normal distribution</h2>
<ul>
  <li>One-variable</li>
</ul>
<div class="mathblock"><script type="math/tex; mode=display">
f(x) = \frac{1}{\sqrt{2\pi} \sigma} e^{-\frac{(x-\mu)^2}{2\sigma^2}}
</script></div>

<ul>
  <li>Multi-variables</li>
</ul>
<div class="mathblock"><script type="math/tex; mode=display">
f(X=x_1,...,x_n) = \frac{1}{\sqrt{(2\pi)^n |C(X)|}} e^{-\frac{1}{2}(X-\bar X)^T C^{-1}(X)(X-\bar X)}
</script></div>
<p>where <script type="math/tex">|C(X)|</script> is the determinant of covariance matrix C(X). By the way, C(X) is usually denoted as <script type="math/tex">\mathbf{\Sigma}</script> in many literatures.</p>

<div class="mathblock"><script type="math/tex; mode=display">
X = \left[x_1, x_2, ..., x_n \right]^T \\

\bar X = mean \\

C(X) = 
\begin{pmatrix}
cov(x_1, x_1) & cov(x_1, x_2) & ... & cov(x_{n-1}, x_{n}) \\
 & ... & &  \\
cov(x_n, x_1) & cov(x_n, x_2) & ... & cov(x_{n}, x_{n})  \\
\end{pmatrix} 
</script></div>

<p>Refer to <a href="https://en.wikipedia.org/wiki/Multivariate_normal_distribution">here</a> for details.</p>



    </article>
    <span class="print-footer">Miscellaneous - Canyu Le</span>
    <footer>
  <hr class="slender">
  <!-- <ul class="footer&#45;links"> -->
  <!--   <li><a href="mailto:hate@spam.net"><span class="icon&#45;mail"></span></a></li>     -->
  <!--    -->
  <!--     <li> -->
  <!--       <a href="//www.twitter.com/twitter_handle"><span class="icon-twitter"></span></a> -->
  <!--     </li> -->
  <!--    -->
  <!--     <li> -->
  <!--       <a href="//plus.google.com/+googlePlusName"><span class="icon-googleplus"></span></a> -->
  <!--     </li> -->
  <!--    -->
  <!--     <li> -->
  <!--       <a href="//github.com/GithubHandle"><span class="icon-github"></span></a> -->
  <!--     </li> -->
  <!--    -->
  <!--     <li> -->
  <!--       <a href="//www.flickr.com/photos/FlickrUserID"><span class="icon-flickr"></span></a> -->
  <!--     </li> -->
  <!--    -->
  <!--     <li> -->
  <!--       <a href="/feed"><span class="icon-feed"></span></a> -->
  <!--     </li> -->
  <!--      -->
  <!-- </ul> -->
<div class="credits">
<!-- <span>&#38;copy; 2018 <!&#45;&#45; &#38;#38;nbsp;&#38;#38;nbsp;CANYU LE &#45;&#45;></span></br> <br> -->
<span>Site created with <a href="//jekyllrb.com">Jekyll</a> using the <a href="//github.com/clayh53/tufte-jekyll">Tufte theme</a>. &copy; 2018</span> 
</div>  
</footer>

  </body>
</html>
