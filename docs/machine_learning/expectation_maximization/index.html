<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Expectation Maximization</title>
  <meta name="description" content="Personal notes (memorandum).">


  <link rel="stylesheet" href="/Notes/css/tufte.css">	
  

  <!-- Google Fonts loaded here depending on setting in _data/options.yml true loads font, blank does not-->
  
    <link href='//fonts.googleapis.com/css?family=Lato:400,400italic' rel='stylesheet' type='text/css'>
  
  <!-- Load up MathJax script if needed ... specify in /_data/options.yml file-->
  
    <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  

  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-75587219-1', 'auto');
  ga('send', 'pageview');

  </script>

  <link rel="canonical" href="http://localhost:4000/Notes/machine_learning/expectation_maximization/">
  <link rel="alternate" type="application/rss+xml" title="Notes" href="http://localhost:4000/Notes/feed.xml" />
</head>

  <body>
    <!--- Header and nav template site-wide -->
<header>
    <nav class="group">
        <a href="/Notes/">Contents</a>
		<a href="https://github.com/Lecanyu/Notes">Github</a>
	</nav>
</header>

    <article class="group">
      <h1>Expectation maximization</h1>
<p class="subtitle"></p>


<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    TeX: {
      Macros: {
        e: "\\epsilon",
        xti: "x^{(i)}",
        yti: "y^{(i)}",
        bfy: "{\\bf y}",
        bfx: "{\\bf x}",
        bfg: "{\\bf g}",
        bfbeta: "{\\bf \\beta}",
        tp: "\\tilde p",
        pt: "p_\\theta",
        Exp: "{\\mathbb{E}}",
        Ind: "{\\mathbb{I}}",
        KL: "{\\mathbb{KL}}",
        Dc: "{\\mathcal{D}}",
        Tc: "{\\mathcal{T}}",
        Xc: "{\\mathcal{X}}",
        note: ["\\textcolor{blue}{[NOTE: #1]}",1]
      }
    }
  });
</script>


<p>Expectation Maximization (a.k.a. EM algorithm) is popular in estimating parameters in model which contains hidden random variable.</p>

<p>I give a specific example which is simple and intuitive to explain the principle here.</p>

<p>For more advanced techniques about EM algorithm, you may refer to <统计学习方法></统计学习方法></p>

<h2 id="硬币模型例子">硬币模型例子</h2>
<p>假设有三枚硬币A、B、C，它们正面朝上的概率是<script type="math/tex">\pi, p, q</script>，按如下规则掷硬币：先掷硬币A，如果A正面朝上则选择硬币B进行投掷，如果A反面朝上则选择硬币C进行投掷，最后记录B或者C的投掷结果作为输出。
这样独立重复地进行n次实验，可得到一系列观测结果<script type="math/tex">Y</script>(比如<script type="math/tex">Y=1101001</script>，1表示正面朝上)。</p>

<p>假如只能观察到硬币最后的投掷结果，而不知道投掷过程中的隐变量，现在想通过观测结果估计硬币模型的参数(即<script type="math/tex">\pi, p, q</script>)，该如何进行？</p>

<p>该问题可用概率模型进行形式化描述：</p>
<div class="mathblock"><script type="math/tex; mode=display">
P(y|\theta) = \sum_z P(y, z|\theta) = \sum_z P(z|\theta)P(y|z,\theta)
</script></div>
<p>这里<script type="math/tex">z</script>表示隐变量，<script type="math/tex">y</script>表示模型输出结果，<script type="math/tex">\theta=(\pi, p, q)</script>是模型参数。
该模型符合直觉，第一项<script type="math/tex">P(z|\theta)</script>的含义是当已知参数时，隐变量取某值的概率。
第二项<script type="math/tex">P(y|z,\theta)</script>的含义是当隐变量和模型参数确定时，产生最终输出的概率。</p>

<p>在硬币模型例子中，分别考虑<script type="math/tex">z</script>的正反两种取值</p>
<div class="mathblock"><script type="math/tex; mode=display">
P(y|\theta) = \sum_z P(z|\theta)P(y|z,\theta) = \pi p^y (1-p)^{(1-y)} + (1-\pi) q^y (1-q)^{(1-y)}
</script></div>

<p>对于一系列的某观测结果发生的概率是</p>
<div class="mathblock"><script type="math/tex; mode=display">
\prod_{i=1}^n P(y_i|\theta) = \prod_{i=1}^n \pi p^{y_i} (1-p)^{(1-y_i)} + (1-\pi) q^{y_i} (1-q)^{(1-y_i)}
</script></div>

<p>进行极大似然估计，取对数可以得到下面的目标函数</p>
<div class="mathblock"><script type="math/tex; mode=display">
f(\theta) = \arg\max_{\theta} \log \prod_{i=1}^n P(y_i|\theta) => f(\pi, p, q) = \arg\max_{\pi, p, q} \sum_{i=1}^n \log (\pi p^{y_i} (1-p)^{(1-y_i)} + (1-\pi) q^{y_i} (1-q)^{(1-y_i)})
</script></div>

<p>一个自然的想法是，对目标函数关于各个参数求偏导，并令偏导数为0即可。
不过这里</p>
<div class="mathblock"><script type="math/tex; mode=display">
\frac{\partial f(\pi, p, q)}{\partial \pi} = \sum_{i=1}^n \frac{p^{y_i} (1-p)^{(1-y_i)} - q^{y_i} (1-q)^{(1-y_i)}}{\pi p^{y_i} (1-p)^{(1-y_i)} + (1-\pi) q^{y_i} (1-q)^{(1-y_i)}}
</script></div>
<p>是否等于0不受<script type="math/tex">\pi</script>控制，也就是说<script type="math/tex">\pi</script>没有最优解析解，对于这个目标函数通常需要用初值迭代的方式进行。</p>

<h3 id="em算法迭代">EM算法迭代</h3>

<p>E步:用当前的参数估计值来估计隐变量的概率分布</p>
<div class="mathblock"><script type="math/tex; mode=display">
P(Z|Y, \theta_i)
</script></div>
<p>放到这个硬币模型中来说就是在给定观测<script type="math/tex">Y=y_i</script>和参数<script type="math/tex">\theta_i</script>的情况下，计算<script type="math/tex">P(Z=z_i|Y=y_i, \theta_i)</script>即第二次掷的是硬币B还是硬币C的概率。</p>

<p>M步:计算<script type="math/tex">\log P(Y,Z|\theta)</script>关于估计得到的隐变量的期望，使该期望最大化，即</p>
<div class="mathblock"><script type="math/tex; mode=display">
\arg\max_{\theta} \sum_{Z} P(Z|Y, \theta_i) \log P(Y, Z|\theta)
</script></div>

<p>E步很符合直觉，而M步初看之下似乎是反直觉的。
为什么要计算<script type="math/tex">\log P(Y,Z|\theta)</script>关于估计得到的隐变量的期望，这样一个奇怪的东西。</p>

<p>直觉上讲，E步估计了隐变量的概率分布之后，
直接用这个隐变量结果来让<script type="math/tex">P(Y|Z, \theta)</script>最大化不就行了吗？
（半监督学习中的伪标签策略就是这样做的）
<label for="1," class="margin-toggle sidenote-number"></label><input type="checkbox" id="1," class="margin-toggle" /><span class="sidenote">注意这种是对EM算法最常见的错误理解，我之前也是这么认为的。  </span></p>

<p>但这种理解是自训练，而并不是EM算法。
M步中奇怪的<script type="math/tex">\log P(Y,Z|\theta)</script>背后是有数学原因的。</p>

<h3 id="em算法的导出">EM算法的导出</h3>

<p>对于一个包含隐变量的概率模型，目标是进行观测数据对参数的极大似然估计</p>

<div class="mathblock"><script type="math/tex; mode=display">
\arg\max_{\theta} L(\theta) = \log P(Y|\theta) = \log \sum_{Z} P(Z|\theta)P(Y|Z, \theta)
</script></div>

<p>由于这里含有求和（或者积分）的对数，这给目标函数的优化带来了困难。
而EM算法并不直接优化上式，而是希望逐渐的使得<script type="math/tex">L(\theta)</script>增大（迭代式的优化）
即 <script type="math/tex">L(\theta_{i+1}) - L(\theta_i) > 0</script>（第i+1次迭代比第i次大）,
为了视觉上容易区分，下面的推导用<script type="math/tex">\theta</script>代替<script type="math/tex">\theta_{i+1}</script>
<label for="1," class="margin-toggle sidenote-number"></label><input type="checkbox" id="1," class="margin-toggle" /><span class="sidenote">这里的推导用了Jensen不等式: <script type="math/tex">\log \sum_i k_i y_i \geq \sum_i k_i \log y_i</script>，其中<script type="math/tex">k_i \geq 0, \sum_i k_i = 1</script>。  </span></p>

<div class="mathblock"><script type="math/tex; mode=display">
L(\theta) - L(\theta_i) = \log[\sum_Z P(Y|Z, \theta)P(Z|\theta)] - \log P(Y|\theta_i) \\
= \log[ \sum_Z P(Z|Y, \theta_{i}) \frac{P(Y|Z, \theta)P(Z|\theta)}{P(Z|Y, \theta_{i})} ] - \log P(Y|\theta_i) \\
\geq \sum_Z P(Z|Y, \theta_{i}) \log \frac{P(Y|Z, \theta)P(Z|\theta)}{P(Z|Y, \theta_{i})} - \log P(Y|\theta_i) \\
= \sum_Z P(Z|Y, \theta_{i}) \log P(Y|Z, \theta)P(Z|\theta) - \sum_Z P(Z|Y, \theta_{i}) \log P(Z|Y, \theta_{i}) - \log P(Y|\theta_i)
</script></div>

<p>我们希望使得每次迭代<script type="math/tex">L(\theta)</script>尽可能大，因此我们可以最大化<script type="math/tex">L(\theta) - L(\theta_i)</script>。
注意到上面推导最后一行只有第一项与<script type="math/tex">\theta</script>有关，因此问题等价于求解</p>
<div class="mathblock"><script type="math/tex; mode=display">
\arg\max_{\theta} L(\theta) - L(\theta_i) = \arg\max_{\theta} \sum_Z P(Z|Y, \theta_{i}) \log P(Y|Z, \theta)P(Z|\theta) \\
= \arg\max_{\theta} \sum_Z P(Z|Y, \theta_{i}) \log P(Y, Z|\theta)
</script></div>
<p>这个就是上面的计算<script type="math/tex">\log P(Y,Z|\theta)</script>关于估计
得到的隐变量的期望<script type="math/tex">\arg\max_{\theta} \sum_{Z} P(Z|Y, \theta_i) \log P(Y, Z|\theta)</script></p>

<p>至此，我们说明了为什么EM算法的M步要计算关于隐变量的期望最大化。
从上面的推导也不难发现，EM的本质是不断的迭代提升<script type="math/tex">L(\theta)</script>的下界来近似最大化的。</p>




    </article>
    <span class="print-footer">Expectation Maximization - Canyu Le</span>
    <footer>
  <hr class="slender">
  <!-- <ul class="footer&#45;links"> -->
  <!--   <li><a href="mailto:hate@spam.net"><span class="icon&#45;mail"></span></a></li>     -->
  <!--    -->
  <!--     <li> -->
  <!--       <a href="//www.twitter.com/twitter_handle"><span class="icon-twitter"></span></a> -->
  <!--     </li> -->
  <!--    -->
  <!--     <li> -->
  <!--       <a href="//plus.google.com/+googlePlusName"><span class="icon-googleplus"></span></a> -->
  <!--     </li> -->
  <!--    -->
  <!--     <li> -->
  <!--       <a href="//github.com/GithubHandle"><span class="icon-github"></span></a> -->
  <!--     </li> -->
  <!--    -->
  <!--     <li> -->
  <!--       <a href="//www.flickr.com/photos/FlickrUserID"><span class="icon-flickr"></span></a> -->
  <!--     </li> -->
  <!--    -->
  <!--     <li> -->
  <!--       <a href="/feed"><span class="icon-feed"></span></a> -->
  <!--     </li> -->
  <!--      -->
  <!-- </ul> -->
<div class="credits">
<!-- <span>&#38;copy; 2020 <!&#45;&#45; &#38;#38;nbsp;&#38;#38;nbsp;CANYU LE &#45;&#45;></span></br> <br> -->
<span>Site created with <a href="//jekyllrb.com">Jekyll</a> using the <a href="//github.com/clayh53/tufte-jekyll">Tufte theme</a>. &copy; 2020</span> 
</div>  
</footer>

  </body>
</html>
