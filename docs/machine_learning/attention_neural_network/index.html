<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Attention neural network</title>
  <meta name="description" content="Personal notes (memorandum).">


  <link rel="stylesheet" href="/Notes/css/tufte.css">	
  

  <!-- Google Fonts loaded here depending on setting in _data/options.yml true loads font, blank does not-->
  
    <link href='//fonts.googleapis.com/css?family=Lato:400,400italic' rel='stylesheet' type='text/css'>
  
  <!-- Load up MathJax script if needed ... specify in /_data/options.yml file-->
  
    <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  

  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-75587219-1', 'auto');
  ga('send', 'pageview');

  </script>

  <link rel="canonical" href="http://localhost:4000/Notes/machine_learning/attention_neural_network/">
  <link rel="alternate" type="application/rss+xml" title="Notes" href="http://localhost:4000/Notes/feed.xml" />
</head>

  <body>
    <!--- Header and nav template site-wide -->
<header>
    <nav class="group">
        <a href="/Notes/">Contents</a>
		<a href="https://lecanyu.github.io/">Resume</a>
		<a href="https://github.com/Lecanyu/Notes">Github</a>
	</nav>
</header>

    <article class="group">
      <h1>Attention neural network</h1>
<p class="subtitle"></p>


<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    TeX: {
      Macros: {
        e: "\\epsilon",
        xti: "x^{(i)}",
        yti: "y^{(i)}",
        bfy: "{\\bf y}",
        bfx: "{\\bf x}",
        bfg: "{\\bf g}",
        bfbeta: "{\\bf \\beta}",
        tp: "\\tilde p",
        pt: "p_\\theta",
        Exp: "{\\mathbb{E}}",
        Ind: "{\\mathbb{I}}",
        KL: "{\\mathbb{KL}}",
        Dc: "{\\mathcal{D}}",
        Tc: "{\\mathcal{T}}",
        Xc: "{\\mathcal{X}}",
        note: ["\\textcolor{blue}{[NOTE: #1]}",1]
      }
    }
  });
</script>


<h2 id="motivation"><strong><em>Motivation</em></strong></h2>

<p>When input data are massive and noisy, it may not be a good idea to directly train a model from the whole of original data. Because it is difficult for models to capture the meaningful information behind the massive data.</p>

<p>For example, in my previous work on jigsaw puzzle solving, it is important to transfer the calculation to the stiching area instead of the whole fragment. In NLP field, it is unnecessary to seize all context to translate a few of local words.</p>

<p>Generally, human’s perceptual system also focus on some particular areas to obtain information.</p>

<h2 id="soft-selection-and-hard-selection"><strong><em>Soft selection and hard selection</em></strong></h2>

<p>Researchers have realized the importance of attention, and they have proposed two approaches to fulfill attention mechanism.</p>

<ol>
  <li>
    <p>Soft selection.</p>

    <p>The selection (attention transferring) layer is differentiable, and thus the whole networks can be trained end to end.</p>
  </li>
  <li>
    <p>Hard selection</p>

    <p>The selection layer is not differentiable. A typical implementation of this layer is  reinforcement learning.</p>
  </li>
</ol>

<p>Here are the representive network structures for these two type selections 
<label for="1" class="margin-toggle sidenote-number"></label><input type="checkbox" id="1" class="margin-toggle" /><span class="sidenote">A nice explaination about attention network can be found <a href="https://blog.heuritech.com/2016/01/20/attention-mechanism/">HERE</a> </span></p>

<figure><figcaption></figcaption><img src="/Notes/assets/machine_learning/attention_network1.png" /></figure>
<p>Left picture: soft selection, right picture: hard selection, the random choice can be learned by a reinforcement learning.</p>

<p>In image captioning, the complete network structure can be below picture.</p>
<figure><figcaption></figcaption><img src="/Notes/assets/machine_learning/attention_network_global.png" /></figure>

<p>The attention model (purple blocks) is the selection layer. <script type="math/tex">h_1, h_2, ..., h_{k-1}</script> is the input <script type="math/tex">c</script> in above two pictures.</p>

<p>LSTM are recurrent neural network modules, which convert the feature map into captions.</p>

<p>The intuition is that the attention model picks some input from feature map vector <script type="math/tex">y_1, y_2, ..., y_n</script> (because softmax is easily dominated by the maximum one).</p>

<p>If you have difficult to understand, go to the original introduction <a href="https://blog.heuritech.com/2016/01/20/attention-mechanism/">HERE</a>.</p>

<h2 id="some-insights-about-structured-attention-networks"><strong><em>Some insights about Structured Attention Networks</em></strong></h2>

<p>Here I’d like to tell some insights about the paper “Structured Attention Networks”. <label for="2" class="margin-toggle sidenote-number"></label><input type="checkbox" id="2" class="margin-toggle" /><span class="sidenote">Kim, Yoon, et al. <a href="https://arxiv.org/pdf/1702.00887.pdf">Structured attention networks</a>. ICLR 2017 </span></p>

<p>The key contribution in this paper is that the authors use a CRF to model the attention layer.</p>

<p>In this paper, the author use below formulation to generalize the attention framework.</p>

<div class="mathblock"><script type="math/tex; mode=display">
c = \mathbb{E}_{z \sim p(z|x,q)}[f(x,z)] = \sum_{i=1}^n p(z=i|x, q) x_i 
\quad \textsf{(original version in paper)} \\

z = \mathbb{E}_{s \sim p(s|y, c)}[f(y, s)] = \sum_{i=1}^n p(s=i|y, c)y_i
\quad \textsf{(use annotations in above pictures)} \\

</script></div>

<p>For consistency, I will use the same annotation in above pictures to explain.
The <script type="math/tex">s\sim p(s|y,c)</script> is the attention distribution. It assigns different weights to the input <script type="math/tex">y_i</script>. <script type="math/tex">c</script> is the so-called query, which is the output <script type="math/tex">h_1, h_2, ..., h_{k-1}</script> in above network structure (i.e. the medium output of RNN). <script type="math/tex">f(y, s)</script> is annotation function which generate a output by combining original input <script type="math/tex">y</script> and attention distribution <script type="math/tex">s</script>. In above example, the <script type="math/tex">f(y, s) = ys</script>.</p>

<p>In this paper, the authors proposed that we can apply a CRF to describe the relationship among all of <script type="math/tex">y, s</script>. As the figure showing below, the red box can be substituded by a CRF. Therefore, we will have</p>
<div class="mathblock"><script type="math/tex; mode=display">
z = \mathbb{E}_{s \sim p(s|y, c)}[f(y, s)] = \sum_C \mathbb{E}_{s \sim p(s_C|y, c)}[f_C(y, s_C)]
</script></div>
<p>where the <script type="math/tex">C</script> indicates the maximum clique.
The above example can be seen as a special case of this model, since the CRF allows the dependence between different <script type="math/tex">s_i</script>. Hence, it is more robust to describe the real probabilistic distribution.</p>

<figure><figcaption></figcaption><img src="/Notes/assets/machine_learning/structured_attention_network.png" /></figure>

<p><strong><em>Note: now my understanding may be wrong. I need to further read and double check.</em></strong></p>




    </article>
    <span class="print-footer">Attention neural network - Canyu Le</span>
    <footer>
  <hr class="slender">
  <!-- <ul class="footer&#45;links"> -->
  <!--   <li><a href="mailto:hate@spam.net"><span class="icon&#45;mail"></span></a></li>     -->
  <!--    -->
  <!--     <li> -->
  <!--       <a href="//www.twitter.com/twitter_handle"><span class="icon-twitter"></span></a> -->
  <!--     </li> -->
  <!--    -->
  <!--     <li> -->
  <!--       <a href="//plus.google.com/+googlePlusName"><span class="icon-googleplus"></span></a> -->
  <!--     </li> -->
  <!--    -->
  <!--     <li> -->
  <!--       <a href="//github.com/GithubHandle"><span class="icon-github"></span></a> -->
  <!--     </li> -->
  <!--    -->
  <!--     <li> -->
  <!--       <a href="//www.flickr.com/photos/FlickrUserID"><span class="icon-flickr"></span></a> -->
  <!--     </li> -->
  <!--    -->
  <!--     <li> -->
  <!--       <a href="/feed"><span class="icon-feed"></span></a> -->
  <!--     </li> -->
  <!--      -->
  <!-- </ul> -->
<div class="credits">
<!-- <span>&#38;copy; 2019 <!&#45;&#45; &#38;#38;nbsp;&#38;#38;nbsp;CANYU LE &#45;&#45;></span></br> <br> -->
<span>Site created with <a href="//jekyllrb.com">Jekyll</a> using the <a href="//github.com/clayh53/tufte-jekyll">Tufte theme</a>. &copy; 2019</span> 
</div>  
</footer>

  </body>
</html>
